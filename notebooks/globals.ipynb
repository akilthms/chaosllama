{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text(\"CATALOG\", \"\")\n",
    "dbutils.widgets.text(\"SCHEMA\", \"\")\n",
    "dbutils.widgets.text(\"MAX_TOKENS\", \"200\")\n",
    "dbutils.widgets.text(\"TRIGGER_RUN\", \"False\")\n",
    "dbutils.widgets.text(\"CLEAN_UP\", \"False\")\n",
    "dbutils.widgets.text(\"TRIGGER_SCALE_TEST\", \"False\")\n",
    "\n",
    "dbutils.widgets.text(\"LIMIT\", \"1\")\n",
    "dbutils.widgets.text(\"CONSISTENCY_FACTOR\", \"1\")\n",
    "dbutils.widgets.text(\"EPOCHS\", \"1\")\n",
    "dbutils.widgets.text(\"BATCH_SIZE\", \"5\")\n",
    "dbutils.widgets.text(\"N_JOBS\", \"8\")\n",
    "dbutils.widgets.text(\"VALIDATION_SET_LIMIT\", \"20\")\n",
    "\n",
    "dbutils.widgets.dropdown(\"Introspection LLM Endpoint\",\n",
    "                         defaultValue='databricks-meta-llama-3-3-70b-instruct',\n",
    "                         choices=[\"databricks-meta-llama-3-3-70b-instruct\", \"databricks-claude-3-7-sonnet\",\n",
    "                                  'databricks-llama-4-maverick'])\n",
    "\n",
    "dbutils.widgets.dropdown(\"JUDGE_LLM_ENDPOINT\",\n",
    "                         defaultValue='databricks-llama-4-maverick',\n",
    "                         choices=['databricks-llama-4-maverick', \"databricks-meta-llama-3-3-70b-instruct\",\n",
    "                                  \"databricks-claude-3-7-sonnet\"])\n",
    "\n",
    "dbutils.widgets.dropdown(\"SMALL_LLM_ENDPOINTS\",\n",
    "                         defaultValue='databricks-meta-llama-3-1-405b-instruct',\n",
    "                         choices=['databricks-meta-llama-3-1-8b-instruct', \"databricks-mixtral-8x7b-instruct\",\n",
    "                                  \"databricks-meta-llama-3-1-405b-instruct\", \"databricks-llama-4-maverick\"])\n",
    "\n",
    "dbutils.widgets.text(\"EXPERIMENT_ID\", \"713974745739565\")\n",
    "dbutils.widgets.text(\"RUN_BASELINE\", \"False\")\n",
    "dbutils.widgets.text(\"REFRESH_DASHBOARD\", \"False\")\n",
    "dbutils.widgets.text(\"INTROSPECTION_LOOKBACK\", \"3\")\n",
    "dbutils.widgets.text(\"DEBUG\", \"False\")\n",
    "dbutils.widgets.text(\"IS_TRIGGERED_FROM_CHECKPOINT\", \"False\")\n",
    "\n",
    "# ðŸ¦™ Chaos LLama Parameters\n",
    "IS_TRIGGERED_FROM_CHECKPOINT = dbutils.widgets.get(\"IS_TRIGGERED_FROM_CHECKPOINT\").lower() == \"true\"\n",
    "DEBUG = dbutils.widgets.get(\"DEBUG\").lower() == \"true\"\n",
    "REFRESH_DASHBOARD = (dbutils.widgets.get(\"REFRESH_DASHBOARD\").lower() == \"true\")\n",
    "SMALL_LLM_ENDPOINTS = dbutils.widgets.get(\"SMALL_LLM_ENDPOINTS\")\n",
    "LIMIT = int(dbutils.widgets.get(\"LIMIT\"))\n",
    "VALIDATION_SET_LIMIT = int(dbutils.widgets.get(\"VALIDATION_SET_LIMIT\"))\n",
    "CONSISTENCY_FACTOR = int(dbutils.widgets.get(\"CONSISTENCY_FACTOR\"))\n",
    "EPOCHS = int(dbutils.widgets.get(\"EPOCHS\"))\n",
    "BATCH_SIZE = int(dbutils.widgets.get(\"BATCH_SIZE\"))\n",
    "N_JOBS = int(dbutils.widgets.get(\"N_JOBS\"))\n",
    "MAX_TOKENS = int(dbutils.widgets.get(\"MAX_TOKENS\"))\n",
    "RUN_BASELINE = dbutils.widgets.get(\"RUN_BASELINE\").lower() == \"true\"\n",
    "EVAL_TABLE_NAME = dbutils.widgets.get(\"EVAL_TABLE_NAME\")\n",
    "# Data Module\n",
    "CATALOG = dbutils.widgets.get(\"CATALOG\")\n",
    "SCHEMA = dbutils.widgets.get(\"SCHEMA\")\n",
    "TRIGGER_RUN = dbutils.widgets.get(\"TRIGGER_RUN\").lower() == \"true\"\n",
    "TRIGGER_SCALE_TEST = dbutils.widgets.get(\"TRIGGER_SCALE_TEST\").lower() == \"true\"\n",
    "CLEAN_UP = dbutils.widgets.get(\"CLEAN_UP\").lower() == \"true\"\n",
    "EVAL_TABLE = f\"{CATALOG}.{SCHEMA}.{EVAL_TABLE_NAME}\"\n",
    "JUDGES_TABLE = f\"{CATALOG}.{SCHEMA}.judges\"\n",
    "CHAOS_ANALYTICS_TABLE = f\"{CATALOG}.{SCHEMA}.chaos_analytics\"\n",
    "\n",
    "BASELINE_SCHEMA = \"sem_glbl_fincl_cpgpt\"\n",
    "# AI/ML Module\n",
    "EXPERIMENT_NAME = \"\"\n",
    "EXPERIMENT_ID = dbutils.widgets.get(\"EXPERIMENT_ID\")\n",
    "LLM = \"\"\n",
    "LLM_PARAMETERS = {\"temperature\": 0.0}\n",
    "HOST = \"https://adb-6209649103177418.18.azuredatabricks.net\"\n",
    "INTROSPECT_AGENT_LLM_ENDPOINT = dbutils.widgets.get(\"Introspection LLM Endpoint\")\n",
    "AI_QUERY_ENDPOINT = \"databricks-meta-llama-3-3-70b-instruct\"\n",
    "JUDGE_LLM_ENDPOINT = dbutils.widgets.get(\"JUDGE_LLM_ENDPOINT\")\n",
    "TEST_TABLE = f\"{CATALOG}.{SCHEMA}.market_dim\"\n",
    "\n",
    "GENIE_SPACE_ID = \"01f004e394f21cdbafb2a1df68f53c3b\"\n",
    "CPGPT_GENIE_SPACE_ID_WITH_DATA_SAMPLING = \"01effdc9c84518888b036a015a4924b7\"\n",
    "CPGPT_GENIE_SPACE_ID_WITHOUT_DATA_SAMPLING = \"01efed4c07061097bbd9330461a22b9f\"\n",
    "DBRX_CPGPT_GENIE_SPACE_ID_WITH_DATA_SAMPLING = \"01f00e773a2e19f9ab163cc576bde01f\"\n",
    "MANUAL_DBRX_CPGPT_GENIE_SPACE_ID_WITH_DATA_SAMPLING = \"01f015947d28105cb6da1f044b7f7c47\"\n",
    "INTROSPECTION_LOOKBACK = int(dbutils.widgets.get(\"INTROSPECTION_LOOKBACK\"))\n",
    "\n",
    "QUALITY_THRESHOLD = .90  # 90%\n",
    "\n",
    "NULL_HYPOTHESIS_GENIE_SPACE_ID = \"01f0086525d917ddb7527333c5af68ba\"\n",
    "\n",
    "METRICS_DEFINITION = \"\"\"\n",
    "SQL Accuracy: The response query does not match the expected query in terms of metrics, countries, and years.\n",
    "Dimension Ambiguity: The response uses different dimension tables than those specified in the request.\n",
    "Correctness: The response does not match the context of the question or the expected response.\n",
    "Guideline Adherence: The response does not address issues with multiple columns and omits necessary filters.\n",
    "\"\"\"\n",
    "\n",
    "BEST_MLFLOW_RUN = \"stately-hound-205\"\n",
    "BEST_MLFLOW_RUN_PROVING_IMPROVEMENT = \"persistent-snipe-320\"\n",
    "\n",
    "BEST_MLFLOW_RUN_AT_SCALE = \"6322d6636e0d4c478fffba1fabc456e5\"\n",
    "\n",
    "BEST_MLFLOW_RUNS_MAP = {\n",
    "    \"skittish-croc-724\": \"3ed7d94979bc4764beea08b3ea07b547\"  # \"20 EPOCHs, 70pct accurarcy, 20 questions\"\n",
    "}\n",
    "\n",
    "MLFLOW_EXPERIMENTS = {\n",
    "    \"Benchmark Lab\": \"283295167155400\",\n",
    "    \"ðŸ¦™ChaosLlama\": \"713974745739565\"\n",
    "}\n",
    "\n",
    "DDL_HISTORY_TABLE = \"ddl_history\"\n",
    "\n",
    "GLOBAL_GUIDELINES = dict(\n",
    "    global_guidelines={\n",
    "        \"sql_accuracy\": [\"Ensure that response and the ground truth are semantically equivalent in ansi spark sql\"],\n",
    "        \"count_joins\": [\"Count the number of joins are the same in both queries.\"],\n",
    "        \"dimension_ambiguity\": [\"Identify if the query chooses the wrong dimension table\"],\n",
    "        \"has_select\": [\n",
    "            \"Ensure that the expected response has a sql SELECT statement , ignoring case, in the ansi sql query\"],\n",
    "        \"financial_planning\": [\n",
    "            \"For every generated query the following dimensions MUST BE PRESENT. Dimensions: [scenario, report_type, year]\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "GLOBAL_GUIDELINES_v2 = dict(\n",
    "    global_guidelines={\n",
    "        \"sql_accuracy\": [\"Ensure that response and the ground truth are semantically equivalent in ansi spark sql\"],\n",
    "        \"count_joins\": [\"Count the number of joins are the same in both queries.\"],\n",
    "        \"has_select\": [\n",
    "            \"Ensure that the expected response has a sql SELECT statement , ignoring case, in the ansi sql query\"],\n",
    "        \"financial_planning\": [\n",
    "            \"For every generated query the following dimensions MUST BE PRESENT. Dimensions: [scenario, report_type, year]\"]\n",
    "    }\n",
    ")\n",
    "w = WorkspaceClient()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
